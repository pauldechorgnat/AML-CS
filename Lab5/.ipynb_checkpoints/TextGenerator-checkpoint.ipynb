{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_DATA = \"texts/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Goethe.txt', 'Hamlet.txt', 'Alighieri.txt', 'Dostoevsky.txt']\n"
     ]
    }
   ],
   "source": [
    "print(os.listdir(PATH_TO_DATA))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "with open(os.path.join(PATH_TO_DATA, 'Alighieri.txt'), \"r\", encoding = \"utf-8\") as file:\n",
    "    for line in file.readlines():\n",
    "        for character in str(line):\n",
    "            data.append(character)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Computing Raw frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "distribution = {}\n",
    "\n",
    "for character in data:\n",
    "    distribution[character] = distribution.get(character, 0)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextGenerator():\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.every_distribution = {}\n",
    "        self.distribution = {}\n",
    "        self.data = []\n",
    "        self.nb_of_characters = 0\n",
    "        self.vocabulary_size = 0\n",
    "    \n",
    "    def load_data(self, path, case_sensitive = True, only_alpha = False):\n",
    "        self.path = path\n",
    "        \n",
    "        data = []\n",
    "        with open(path, \"r\", encoding = \"utf-8\") as file:\n",
    "            for line in file.readlines():\n",
    "                \n",
    "                line_str = str(line).replace(\"\\n\", \"\")\n",
    "                \n",
    "                if not case_sensitive :\n",
    "                    line_str = str(line).lower()\n",
    "                    \n",
    "                for character in line_str:\n",
    "                    if only_alpha is True:\n",
    "                        if (not character.isalpha()) and  (character != \" \"):\n",
    "                            continue\n",
    "                    data.append(character)\n",
    "        self.data = data\n",
    "        self.nb_of_characters = len(data)\n",
    "        self.vocabulary_size = len(set(data))\n",
    "        print(\"Data Loaded\")\n",
    "        \n",
    "    def compute_sequence_distribution(self, history = 1):\n",
    "            \n",
    "        sequence_distribution = {}\n",
    "        \n",
    "        \n",
    "        for index in range(self.nb_of_characters-history):\n",
    "            sequence = \"\".join(self.data[index:index+history+1])\n",
    "            sequence_distribution[sequence] = sequence_distribution.get(sequence, 0)+1\n",
    "            \n",
    "        for sequence in sequence_distribution.keys():\n",
    "            sequence_distribution[sequence] /= (self.nb_of_characters - history)\n",
    "            \n",
    "        self.every_distribution[history] = sequence_distribution \n",
    "        print(\"Distribution for {}-long sequences computed\".format(history+1))\n",
    "        return sequence_distribution\n",
    "        \n",
    "    def compute_raw_distribution(self):\n",
    "        \n",
    "        self.distribution = self.compute_sequence_distribution(history = 0)\n",
    "        \n",
    "        print(\"Distribution computed\")\n",
    "    \n",
    "    \n",
    "#    def plot_distribution(self, history = 1):\n",
    "#        if history in self.every_distribution.keys():\n",
    "#            plt.figure(figsize = (16,8))\n",
    "#            plt.bar(x = range(0, len(self.every_distribution[history].values()) - history), \n",
    "#                    height = [i for i in self.every_distribution[history].values()])\n",
    "#            plt.xticks(range(self.vocabulary_size), [i for i in self.every_distribution[history].keys()])\n",
    "#            plt.xlabel(\"Vocabulary\")\n",
    "#            plt.ylabel(\"Character probability\")\n",
    "#            plt.show()\n",
    "#        pass\n",
    "    \n",
    "    def generate_character_iid(self):\n",
    "        return np.random.choice(a = [character for character in self.distribution.keys()],\n",
    "                                p = [proba for proba in self.distribution.values()])\n",
    "        \n",
    "    def generate_character_markov(self, current_sequence, history = 2):\n",
    "        if history not in self.every_distribution.keys():\n",
    "            self.compute_sequence_distribution(history)\n",
    "            \n",
    "        probas = []\n",
    "        following_character = []\n",
    "        total_proba = 0\n",
    "        \n",
    "        for sequence, proba in self.every_distribution[history].items():\n",
    "            if current_sequence == sequence[:-1]:\n",
    "                total_proba += proba\n",
    "                probas.append(proba)\n",
    "                following_character.append(sequence[-1])\n",
    "        \n",
    "        # if the sequence has never happened, we can just generate a random number\n",
    "        if total_proba == 0:\n",
    "            return self.generate_character_iid()\n",
    "        else:\n",
    "            return np.random.choice(a = following_character, p = np.array(probas)/total_proba)\n",
    "        \n",
    "\n",
    "    def generate_text(self, method = 'iid', history = 4, length = 1000, initial_string = None):\n",
    "\n",
    "        output_string = \"\"\n",
    "        if method == 'iid':\n",
    "\n",
    "            # if we want to enter an initial string to complete\n",
    "            if initial_string is None:\n",
    "                output_string = ''\n",
    "            else :\n",
    "                output_string = initial_string\n",
    "\n",
    "            # generating independant characters\n",
    "            output_string += ''.join([self.generate_character_iid() for i in range(length)])\n",
    "\n",
    "        else :\n",
    "            # we need the distribution of history+1 long sequences\n",
    "            if history not in self.every_distribution.keys():\n",
    "                self.compute_sequence_distribution(history)\n",
    "\n",
    "            #initialization :\n",
    "            if initial_string is None:\n",
    "                input_sequence = ''.join([self.generate_character_iid() for i in range(history)])\n",
    "                output_string = ''\n",
    "            else:\n",
    "                input_sequence = initial_string[-history:]\n",
    "                output_string = initial_string\n",
    "\n",
    "            # generating the text based on Markov distributions for history long memory\n",
    "            for i in range(length-history):\n",
    "                new_character = self.generate_character_markov(current_sequence=input_sequence, history = history)\n",
    "                input_sequence = input_sequence[1:]+new_character\n",
    "                output_string += new_character\n",
    "\n",
    "        return output_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_gen = TextGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Loaded\n"
     ]
    }
   ],
   "source": [
    "text_gen.load_data(os.path.join(PATH_TO_DATA, 'Alighieri.txt'), case_sensitive=True, only_alpha=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution for 1-long sequences computed\n",
      "Distribution computed\n"
     ]
    }
   ],
   "source": [
    "text_gen.compute_raw_distribution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution for 3-long sequences computed\n"
     ]
    }
   ],
   "source": [
    "_ = text_gen.compute_sequence_distribution(history=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution for 5-long sequences computed\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' '"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_gen.generate_character_markov('la div', history = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_gen.generate_text(method = \"markov\", history = 4, initial_string = 'la div', length = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
