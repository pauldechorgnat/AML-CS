{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_DATA = \"texts/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Goethe.txt', 'Hamlet.txt', 'Alighieri.txt', 'Dostoevsky.txt']\n"
     ]
    }
   ],
   "source": [
    "print(os.listdir(PATH_TO_DATA))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IID Text Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IIDGenerator():\n",
    "    def __init__(self):\n",
    "        self.distribution = {}\n",
    "        self.vocaculary = None\n",
    "        self.vocabulary_size = 0\n",
    "        self.data_size = 0\n",
    "        self.data = []\n",
    "        self.loaded_data = False\n",
    "        self.computed_distribution = False\n",
    "        pass\n",
    "    \n",
    "    def load_data(self, path, case_sensitive = True, only_alpha = False):\n",
    "        self.path = path\n",
    "        \n",
    "        data = []\n",
    "        with open(path, \"r\", encoding = \"utf-8\") as file:\n",
    "            for line in file.readlines():\n",
    "                \n",
    "                line_str = str(line).replace(\"\\n\", \"\")\n",
    "                \n",
    "                if not case_sensitive :\n",
    "                    line_str = str(line).lower()\n",
    "                    \n",
    "                for character in line_str:\n",
    "                    if only_alpha is True:\n",
    "                        if (not character.isalpha()) and  (character != \" \") and  (character != \".\"):\n",
    "                            continue\n",
    "                    data.append(character)\n",
    "        self.data = data\n",
    "        self.data_size = len(data)\n",
    "        self.vocabulary = np.unique(data)\n",
    "        self.vocabulary_size = len(self.vocabulary)\n",
    "        self.loaded_data = True\n",
    "        print(\"Data Loaded\")\n",
    "        pass\n",
    "    \n",
    "    def compute_distribution(self):\n",
    "        distribution = {}\n",
    "        for character in self.data:\n",
    "            distribution[character] = distribution.get(character, 0)+1/self.data_size\n",
    "        self.distribution = distribution\n",
    "        self.computed_distribution = True\n",
    "        print(\"IID distribution computed\")\n",
    "        pass\n",
    "    \n",
    "    def generate_character(self):\n",
    "        if self.computed_distribution is False:\n",
    "            self.compute_distribution()\n",
    "        return np.random.choice(a = [character for character in self.distribution.keys()],\n",
    "                                p = [proba for proba in self.distribution.values()])\n",
    "    \n",
    "    def generate_text(self, length = 100, input_string = ''):\n",
    "        output_string = input_string\n",
    "        for i in range(length):\n",
    "            output_string += self.generate_character()\n",
    "        return output_string\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MarkovGenerator():\n",
    "    def __init__(self, history_size = 1):\n",
    "        self.history_size = history_size\n",
    "        self.iid_generator = None\n",
    "        self.distribution = {}\n",
    "        self.vocaculary = None\n",
    "        self.vocabulary_size = 0\n",
    "        self.data_size = 0\n",
    "        self.data = []\n",
    "        self.loaded_data = False\n",
    "        self.computed_distribution = False\n",
    "        pass\n",
    "    \n",
    "    def load_data(self, path, case_sensitive = True, only_alpha = False):\n",
    "        self.path = path\n",
    "        self.case_sensitive = case_sensitive\n",
    "        self.only_alpha = only_alpha\n",
    "        \n",
    "        data = []\n",
    "        with open(path, \"r\", encoding = \"utf-8\") as file:\n",
    "            for line in file.readlines():\n",
    "                \n",
    "                line_str = str(line).replace(\"\\n\", \"\")\n",
    "                \n",
    "                if not case_sensitive :\n",
    "                    line_str = str(line).lower()\n",
    "                    \n",
    "                for character in line_str:\n",
    "                    if only_alpha is True:\n",
    "                        if (not character.isalpha()) and  (character != \" \") and  (character != \".\"):\n",
    "                            continue\n",
    "                    data.append(character)\n",
    "        \n",
    "        self.data = data\n",
    "        self.data_size = len(data)\n",
    "        self.vocabulary = np.unique(self.data)\n",
    "        self.vocabulary_size = len(self.vocabulary)\n",
    "        self.loaded_data = True\n",
    "        print(\"Data Loaded\")\n",
    "        pass\n",
    "    \n",
    "    def compute_distribution(self):\n",
    "        history = self.history_size\n",
    "        \n",
    "        # compute an iid generator to avoid deadends\n",
    "        self.iid_generator = IIDGenerator()\n",
    "        self.iid_generator.load_data(path = self.path,\n",
    "                                     case_sensitive = self.case_sensitive,\n",
    "                                     only_alpha = self.only_alpha)\n",
    "        self.iid_generator.compute_distribution()\n",
    "        distribution = {}\n",
    "        for index in range(self.vocabulary_size-history):\n",
    "            sequence = \"\".join(self.data[index:index+history+1])\n",
    "            distribution[sequence] = distribution.get(sequence, 0)+ 1 / (self.vocabulary_size - history)\n",
    "            \n",
    "            \n",
    "        self.distribution = distribution\n",
    "        self.computed_distribution = True\n",
    "        print(\"Sequence distribution computed\")\n",
    "        pass\n",
    "    \n",
    "    def generate_character(self, input_sequence, weighted = True):\n",
    "        if not self.computed_distribution:\n",
    "            self.compute_distribution()\n",
    "            \n",
    "        probas = []\n",
    "        following_character = []\n",
    "        total_proba = 0\n",
    "        \n",
    "        for sequence, proba in self.distribution.items():\n",
    "            if input_sequence == sequence[:-1]:\n",
    "                total_proba += proba\n",
    "                probas.append(proba)\n",
    "                following_character.append(sequence[-1])\n",
    "        \n",
    "        # if the sequence has never happened, we can just generate a random number\n",
    "        if total_proba == 0:\n",
    "            if weighted:\n",
    "                return self.iid_generator.generate_character()\n",
    "            else :\n",
    "                return np.random.choice(a = [char for char in self.vocabulary])\n",
    "        else:\n",
    "            return np.random.choice(a = following_character, p = np.array(probas)/total_proba)\n",
    "    \n",
    "    def generate_text(self, length = 100, input_string = '', weighted = True):\n",
    "        history = self.history_size\n",
    "        input_length = len(input_string)\n",
    "        output_string = input_string\n",
    "        \n",
    "        # we need to pad the input string \n",
    "        if input_length < history:\n",
    "            if weighted:\n",
    "                output_string+= self.iid_generator.generate_text(length=history-input_length)\n",
    "            else :\n",
    "                output_string += ''.join(np.random.choice(a = self.vocabulary, \n",
    "                                                          size = history-input_length))\n",
    "        for i in range(length):\n",
    "            # updating the input string\n",
    "            input_sequence = output_string[-history:]\n",
    "            output_string += self.generate_character(input_sequence=input_sequence, weighted = weighted)\n",
    "            \n",
    "        return output_string\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [],
   "source": [
    "iid_gen = IIDGenerator()\n",
    "markov = MarkovGenerator(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Loaded\n",
      "Data Loaded\n",
      "IID distribution computed\n",
      "Sequence distribution computed\n"
     ]
    }
   ],
   "source": [
    "\n",
    "markov.load_data(os.path.join(PATH_TO_DATA, 'Alighieri.txt'), case_sensitive=False, only_alpha=True)\n",
    "markov.compute_distribution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Nel mezzo del cammin di nostra vitafuaoreie ei   t ecgu sas c enms  apchtoep llcsoluirreo imltlcan.qesasiri c  uu  oeahe.ireaetiege  c uspatao slov sclgeti a o ï  ceise rvop èq eu .daaicoeocav n sia oinh in aipeethou rrnivtf aere v xofvoidh.leeeofec minalel a eaoe boese    qcg  aiceeoiq psdueacìre bm u t  lm oa  ad nas noeauoliaiaiobmhu aee oasu sl ng ire f  oti acm  rotoga aenao rndcsicaaidns a toene  n acntnidt  tiainizde a l   ihu  aieii peiii  dlo n  eieelle mai iégtr etlaahv u  ccieee.escls dr so cliieane mcp udiro  esoro taa e  re tu lriuagedaed hnt rtis  noa   etmeout  iu  tcdeaoioii .al o aeideavpmd ihsei rii p ftuoocguda  aeosih a ìiamichrc aeini lsidno  smehfaao s cse etmirla i neeaetcr eiu ec    a.c imeinoaomhv nt  eoo c paentae      ro vntirh nontl deotasualu ooial cioep e lqr no ùa seceneined ein ee os ao bit. s hegfntuu e ie  ailsl rot m h p  iou cpuo t   vloieciin  c  ag l lïplioenoec  rt i epcnar  o ozupcav eim.et ocioon g n aig.ie iitll l ermt.ddeaaehaa aaiasiant  ieecannimaaul  n  n  baes iai  rrhq  ee'"
      ]
     },
     "execution_count": 446,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "markov.generate_text(1000, input_string=\"Nel mezzo del cammin di nostra vita\", weighted=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' ',\n",
       " '.',\n",
       " 'a',\n",
       " 'b',\n",
       " 'c',\n",
       " 'd',\n",
       " 'e',\n",
       " 'f',\n",
       " 'g',\n",
       " 'h',\n",
       " 'i',\n",
       " 'j',\n",
       " 'k',\n",
       " 'l',\n",
       " 'm',\n",
       " 'n',\n",
       " 'o',\n",
       " 'p',\n",
       " 'q',\n",
       " 'r',\n",
       " 's',\n",
       " 't',\n",
       " 'u',\n",
       " 'v',\n",
       " 'w',\n",
       " 'x',\n",
       " 'y',\n",
       " 'z',\n",
       " 'ß',\n",
       " 'ä',\n",
       " 'ö',\n",
       " 'ü']"
      ]
     },
     "execution_count": 382,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-356-4c7285fce6c9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m[\u001b[0m\u001b[0mchar\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mchar\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmarkov\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocaculary\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "[char for char in markov.vocaculary]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
